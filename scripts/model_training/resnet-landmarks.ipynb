{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":671,"status":"ok","timestamp":1733936982150,"user":{"displayName":"Nada Khan","userId":"13243958152653740427"},"user_tz":-480},"id":"2d6y4yuZIIlE","outputId":"01a8c910-4bff-4573-c4bc-897bcb59fcb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Dec 11 17:09:41 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0              50W / 400W |      2MiB / 40960MiB |      0%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11100,"status":"ok","timestamp":1733936993720,"user":{"displayName":"Nada Khan","userId":"13243958152653740427"},"user_tz":-480},"id":"4zy02G4BXhSN","outputId":"856b2896-fb4d-4326-cf74-d22d82fc4c1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting cvzone\n","  Downloading cvzone-1.6.1.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from cvzone) (4.10.0.84)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cvzone) (1.26.4)\n","Building wheels for collected packages: cvzone\n","  Building wheel for cvzone (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cvzone: filename=cvzone-1.6.1-py3-none-any.whl size=26298 sha256=f985026ac36c2af042b212b3f86e8945cfe921f9ee9c523dd47d07cb5a122bac\n","  Stored in directory: /root/.cache/pip/wheels/2c/9f/b3/92e945ac4a71bf727a92463f38155cc5a4fa49c5010b38ec4c\n","Successfully built cvzone\n","Installing collected packages: cvzone\n","Successfully installed cvzone-1.6.1\n","Collecting mediapipe\n","  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n","Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n","Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install cvzone\n","!pip install mediapipe\n","!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34834,"status":"ok","timestamp":1733937028549,"user":{"displayName":"Nada Khan","userId":"13243958152653740427"},"user_tz":-480},"id":"gR0ZXpYjXfeH","outputId":"a24f3433-7770-4a82-f65d-9a9eae1a5083"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6wKRMn3OuNcR"},"outputs":[],"source":["#imports\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import Flatten, Dense\n","from tensorflow.keras.models import Model\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1733937034071,"user":{"displayName":"Nada Khan","userId":"13243958152653740427"},"user_tz":-480},"id":"DVOC_P_kJZM5","outputId":"d899fb6c-6f46-4ef0-93cc-253c8e3d4c0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow is using GPU: /device:GPU:0\n"]}],"source":["# Check if GPU is being used\n","if tf.test.gpu_device_name():\n","    print(f\"TensorFlow is using GPU: {tf.test.gpu_device_name()}\")\n","else:\n","    print(\"TensorFlow is not using the GPU.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFg12z1F3EVM"},"outputs":[],"source":["#paths\n","michael_data_folder = \"/content/drive/MyDrive/50.035 Computer Vision Group Assignment/Data (Combined)/cropped (Mitchel & Ad)/\"\n","landmarks_only_folder = \"/content/drive/MyDrive/50.035 Computer Vision Group Assignment/Data (Combined)/cropped (Mitchel & Ad)/Landmarks (black)\"\n","\n","data_folder = landmarks_only_folder #note to nada: this path currently points at landmarks only, feel free to change if you want to train on diff dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42023,"status":"ok","timestamp":1733937076091,"user":{"displayName":"Nada Khan","userId":"13243958152653740427"},"user_tz":-480},"id":"77u93Nji6L9z","outputId":"3b4abfcb-e961-4100-cbb5-57485a394cb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                            img_path  label\n","0  /content/drive/MyDrive/50.035 Computer Vision ...  tur_N\n","1  /content/drive/MyDrive/50.035 Computer Vision ...  tur_N\n","2  /content/drive/MyDrive/50.035 Computer Vision ...  tur_N\n","3  /content/drive/MyDrive/50.035 Computer Vision ...  tur_N\n","4  /content/drive/MyDrive/50.035 Computer Vision ...  tur_N\n","DataFrame created and saved successfully!\n"]}],"source":["#create csv - note: u only need to run this once btw if u keep retraining the model\n","csv_path = os.path.join(michael_data_folder,'_landmarks_metadata.csv') #note to nada: change this if ur not training landmarks only\n","data = []\n","\n","for filename in os.listdir(data_folder):\n","    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n","        label = filename.split(\" (\")[0]\n","        img_path = os.path.join(data_folder, filename)\n","        data.append({\"img_path\": img_path, \"label\": label})\n","\n","df = pd.DataFrame(data)\n","print(df.head())\n","\n","unique_labels = df['label'].unique()\n","label_map = {label: idx for idx, label in enumerate(unique_labels)}\n","df['numeric_label'] = df['label'].map(label_map)\n","df = df.drop(columns='label')\n","\n","df.to_csv(csv_path, index=False)\n","print(\"DataFrame created and saved successfully!\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1733937076092,"user":{"displayName":"Nada Khan","userId":"13243958152653740427"},"user_tz":-480},"id":"ne8Gr-7qCWS_","outputId":"83c87737-b01e-49f6-d7c5-b70f6894d7b2"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"metadata\",\n  \"rows\": 9555,\n  \"fields\": [\n    {\n      \"column\": \"img_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9555,\n        \"samples\": [\n          \"/content/drive/MyDrive/50.035 Computer Vision Group Assignment/Data (Combined)/cropped (Mitchel & Ad)/Landmarks (black)/bis_F (144).jpg\",\n          \"/content/drive/MyDrive/50.035 Computer Vision Group Assignment/Data (Combined)/cropped (Mitchel & Ad)/Landmarks (black)/bis_C (11).jpg\",\n          \"/content/drive/MyDrive/50.035 Computer Vision Group Assignment/Data (Combined)/cropped (Mitchel & Ad)/Landmarks (black)/tur_T (245).jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"numeric_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 0,\n        \"max\": 47,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          27,\n          40,\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"metadata"},"text/html":["\n","  <div id=\"df-acca1dc6-1b3b-41b8-908d-45e9685290fa\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_path</th>\n","      <th>numeric_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/50.035 Computer Vision ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/50.035 Computer Vision ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/50.035 Computer Vision ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/50.035 Computer Vision ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/50.035 Computer Vision ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acca1dc6-1b3b-41b8-908d-45e9685290fa')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-acca1dc6-1b3b-41b8-908d-45e9685290fa button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-acca1dc6-1b3b-41b8-908d-45e9685290fa');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-22abb8f8-04b1-48bc-b404-7c1a41dca632\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22abb8f8-04b1-48bc-b404-7c1a41dca632')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-22abb8f8-04b1-48bc-b404-7c1a41dca632 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                            img_path  numeric_label\n","0  /content/drive/MyDrive/50.035 Computer Vision ...              0\n","1  /content/drive/MyDrive/50.035 Computer Vision ...              0\n","2  /content/drive/MyDrive/50.035 Computer Vision ...              0\n","3  /content/drive/MyDrive/50.035 Computer Vision ...              0\n","4  /content/drive/MyDrive/50.035 Computer Vision ...              0"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Load the metadata CSV\n","metadata = pd.read_csv(csv_path)\n","\n","# Ensure the 'img_path' column contains full paths to images\n","metadata['img_path'] = metadata['img_path'].apply(lambda x: os.path.join(data_folder, x))\n","metadata.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXfmLzN83O0P"},"outputs":[],"source":["# Split the metadata into training, validation, and test sets\n","train_df = metadata.sample(frac=0.8, random_state=42)  # 80% training\n","remaining_df = metadata.drop(train_df.index)\n","val_df = remaining_df.sample(frac=0.5, random_state=42)  # 50% of remaining = 10% overall\n","test_df = remaining_df.drop(val_df.index)  # Remaining 10% for test\n","\n","# Convert 'numeric_label' to string for compatibility with class_mode='categorical'\n","train_df['numeric_label'] = train_df['numeric_label'].astype(str)\n","val_df['numeric_label'] = val_df['numeric_label'].astype(str)\n","test_df['numeric_label'] = test_df['numeric_label'].astype(str)\n","\n","\n","\n","# # Create ImageDataGenerator instances\n","# train_datagen = ImageDataGenerator(\n","#     rescale=1.0 / 255.0,  # Normalize pixel values\n","#     validation_split=0.2\n","# )\n","# val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n","\n","# train_generator = train_datagen.flow_from_dataframe(\n","#     train_df,\n","#     x_col='img_path',\n","#     y_col='numeric_label',\n","#     target_size=(224, 224),\n","#     batch_size=32,\n","#     class_mode='categorical',\n","#     shuffle=True\n","# )\n","\n","# val_generator = val_datagen.flow_from_dataframe(\n","#     val_df,\n","#     x_col='img_path',\n","#     y_col='numeric_label',\n","#     target_size=(224, 224),\n","#     batch_size=32,\n","#     class_mode='categorical',\n","#     shuffle=False\n","# )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"69c59DCTCKSu"},"outputs":[],"source":["# Paths and labels from the DataFrame\n","train_paths = train_df['img_path'].values\n","train_labels = tf.keras.utils.to_categorical(train_df['numeric_label'].astype(int).values)\n","val_paths = val_df['img_path'].values\n","val_labels = tf.keras.utils.to_categorical(val_df['numeric_label'].astype(int).values)\n","test_paths = test_df['img_path'].values\n","test_labels = tf.keras.utils.to_categorical(test_df['numeric_label'].astype(int).values)\n","\n","# Preprocessing function for loading and resizing images\n","def preprocess_image(file_path, label):\n","    image = tf.io.read_file(file_path)\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.resize(image, [224, 224])  # Resize to target size\n","    image = image / 255.0  # Normalize pixel values\n","    return image, label\n","\n","# Create tf.data.Dataset objects\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n","val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n","\n","# Apply preprocessing\n","train_dataset = train_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","val_dataset = val_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","test_dataset = test_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","# Optimize datasets\n","batch_size = 32\n","train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n","val_dataset = val_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n","test_dataset = test_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9524,"status":"ok","timestamp":1733937085611,"user":{"displayName":"Nada Khan","userId":"13243958152653740427"},"user_tz":-480},"id":"hGNl_p1m3RyE","outputId":"dcee5e18-b3ba-441a-e381-6b5476df4664"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"]}],"source":["# Load ResNet50 and modify it for the dataset\n","num_classes = 48\n","\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","x = Flatten()(base_model.output)\n","x = Dense(128, activation='relu')(x)\n","output = Dense(num_classes, activation='softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=output)\n","\n","# Freeze base model layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","for layer in model.layers[-10:]:  # unfreeze last 10 layers\n","    layer.trainable = True\n","\n","\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"UZclRTQQCbNB","outputId":"45be779c-6baa-4421-bdd6-6ec2e21ade72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 100ms/step - accuracy: 0.2284 - loss: 3.1700 - val_accuracy: 0.1862 - val_loss: 3.2771\n","Epoch 2/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.9423 - loss: 0.2772 - val_accuracy: 0.9257 - val_loss: 0.4000\n","Epoch 3/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.9811 - loss: 0.0921 - val_accuracy: 0.9174 - val_loss: 0.3093\n","Epoch 4/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9866 - loss: 0.0717 - val_accuracy: 0.9331 - val_loss: 0.2562\n","Epoch 5/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9869 - loss: 0.0558 - val_accuracy: 0.9833 - val_loss: 0.0846\n","Epoch 6/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9846 - loss: 0.0587 - val_accuracy: 0.9718 - val_loss: 0.1057\n","Epoch 7/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9934 - loss: 0.0348 - val_accuracy: 0.9885 - val_loss: 0.0690\n","Epoch 8/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9856 - loss: 0.0544 - val_accuracy: 0.9718 - val_loss: 0.1076\n","Epoch 9/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9882 - loss: 0.0517 - val_accuracy: 0.9885 - val_loss: 0.0592\n","Epoch 10/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9904 - loss: 0.0360 - val_accuracy: 0.9937 - val_loss: 0.0485\n","Epoch 11/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.9976 - loss: 0.0107 - val_accuracy: 0.9550 - val_loss: 0.1310\n","Epoch 12/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9899 - loss: 0.0399 - val_accuracy: 0.9487 - val_loss: 0.1873\n","Epoch 13/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.9816 - loss: 0.0619 - val_accuracy: 0.9843 - val_loss: 0.0587\n","Epoch 14/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.9923 - loss: 0.0265 - val_accuracy: 0.9623 - val_loss: 0.1633\n","Epoch 15/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9931 - loss: 0.0241 - val_accuracy: 0.9791 - val_loss: 0.0824\n","Epoch 16/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.9909 - loss: 0.0377 - val_accuracy: 0.9749 - val_loss: 0.1247\n","Epoch 17/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9895 - loss: 0.0390 - val_accuracy: 0.9100 - val_loss: 0.3087\n","Epoch 18/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.9931 - loss: 0.0333 - val_accuracy: 0.9969 - val_loss: 0.0267\n","Epoch 19/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.9982 - loss: 0.0090 - val_accuracy: 0.9979 - val_loss: 0.0259\n","Epoch 20/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.4492e-04 - val_accuracy: 0.9969 - val_loss: 0.0252\n"]}],"source":["history = model.fit(train_dataset, validation_data=val_dataset, epochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FX71AKqN3bS9","outputId":"44086d45-4cf8-4d53-bf34-52a0a82ba26c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.9954 - loss: 0.0250\n","Test Set Accuracy: 0.9979057312011719\n"]}],"source":["# evaluate the model on test data\n","test_loss, test_accuracy = model.evaluate(test_dataset)\n","print(f\"Test Set Accuracy: {test_accuracy}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vaqhxIzjPdQ_"},"outputs":[],"source":["def get_labels(dataset):\n","    labels = []\n","    for _, label in dataset:\n","        labels.append(label.numpy())\n","    return np.concatenate(labels)\n","\n","y_true = get_labels(test_dataset)\n","\n","y_pred = np.argmax(model.predict(test_dataset), axis=1)\n","\n","# ensure y_true is a 1D array of class labels (not one-hot encoded)\n","y_true = np.argmax(y_true, axis=1) if y_true.ndim > 1 else y_true\n","\n","cm = confusion_matrix(y_true, y_pred)\n","class_names = list(label_map.keys())\n","\n","\n","# Plot confusion matrix\n","def plot_confusion_matrix(cm, classes):\n","    plt.figure(figsize=(10, 8))\n","    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","    plt.title('Confusion Matrix')\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = 'd'\n","    thresh = cm.max() / 2\n","    for i, j in np.ndindex(cm.shape):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.tight_layout()\n","\n","plot_confusion_matrix(cm, class_names)\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"koGguR0QfwFQ"},"outputs":[],"source":["print(\"Classification Report:\")\n","print(classification_report(y_true, y_pred, target_names=class_names))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2IL1srB9fx6r"},"outputs":[],"source":["# Compute F2 score\n","def fbeta_score(y_true, y_pred, beta=2):\n","    from sklearn.metrics import precision_recall_fscore_support\n","    precision, recall, _, _ = precision_recall_fscore_support(y_true, y_pred, beta=beta, average='weighted')\n","    fbeta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall + 1e-7)\n","    return fbeta\n","\n","f2_score = fbeta_score(y_true, y_pred, beta=2)\n","print(f\"F2 Score: {f2_score}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TbGtrDCTR_9y"},"outputs":[],"source":["model_path = os.path.join(michael_data_folder,'models/resnet_landmarks_only.h5') #note: change this if ur making a copy of the file!!!\n","model.save(model_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IpDQeXHlZYuU"},"outputs":[],"source":["print(label_map)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"authorship_tag":"ABX9TyN0vfZi8UiLEMf5na8iyxc4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}