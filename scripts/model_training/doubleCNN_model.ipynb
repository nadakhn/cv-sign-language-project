{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1x9yzMDzLx0bZ5TCnZlzmfNMGj3MEYT9g","timestamp":1733667406942}],"gpuType":"L4","authorship_tag":"ABX9TyPw4VKGz0eQBkavOsofYlEm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Import and install required libraries/dependencies"],"metadata":{"id":"qwJ8FipNbxxX"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3mZo1yghxhXI","executionInfo":{"status":"ok","timestamp":1734016992328,"user_tz":-480,"elapsed":17697,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"cc98e779-98c0-45b6-b69e-8ba45095018a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install cvzone\n","!pip install mediapipe\n","!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ioi9iRax-dY","executionInfo":{"status":"ok","timestamp":1734017002933,"user_tz":-480,"elapsed":10612,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"f7e7ce10-ca58-46da-b92d-220a419113ab"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting cvzone\n","  Downloading cvzone-1.6.1.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from cvzone) (4.10.0.84)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cvzone) (1.26.4)\n","Building wheels for collected packages: cvzone\n","  Building wheel for cvzone (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cvzone: filename=cvzone-1.6.1-py3-none-any.whl size=26298 sha256=b10dbbc7afa54323273f1241068c7e74d17190669bdce6ce41d34850bbfa2b0e\n","  Stored in directory: /root/.cache/pip/wheels/2c/9f/b3/92e945ac4a71bf727a92463f38155cc5a4fa49c5010b38ec4c\n","Successfully built cvzone\n","Installing collected packages: cvzone\n","Successfully installed cvzone-1.6.1\n","Collecting mediapipe\n","  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n","Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n","Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","from cvzone.HandTrackingModule import HandDetector\n","import pandas as pd\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n","import numpy as np\n","import os, cv2, math\n","import tensorflow as tf"],"metadata":{"id":"gclQujclxnhq","executionInfo":{"status":"ok","timestamp":1734017015616,"user_tz":-480,"elapsed":5866,"user":{"displayName":"Ad","userId":"01421917782521615893"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Model training pipeline"],"metadata":{"id":"XvwGO_BnGCCw"}},{"cell_type":"markdown","source":["## Save the landmark images into processed_csv with filename and labels"],"metadata":{"id":"f7wQTMrgGNbj"}},{"cell_type":"code","source":["black_landmark_img = \"/content/drive/MyDrive/50.035 Computer Vision Group Assignment/Data (Combined)/cropped (Mitchel & Ad)/Landmarks (black)\"\n","\n","data = []\n","\n","for filename in os.listdir(black_landmark_img):\n","    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n","        label = filename.split(\" (\")[0]\n","        if label in [\"bis_C\", \"tur_C\"]:\n","              label = \"bis_tur_C\"\n","        img_path = os.path.join(black_landmark_img, filename)\n","        data.append({\"img_path\": img_path, \"label\": label})\n","\n","df = pd.DataFrame(data)\n","print(df.head())\n","\n","unique_labels = df['label'].unique()\n","label_map = {label: idx for idx, label in enumerate(unique_labels)}\n","df['numeric_label'] = df['label'].map(label_map)\n","df = df.drop(columns='label')\n","\n","df.to_csv(\"/content/drive/MyDrive/CompVision/black_landmarks.csv\", index=False)\n","print(\"DataFrame created and saved successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zQWpEXHGUVR","executionInfo":{"status":"ok","timestamp":1734020650428,"user_tz":-480,"elapsed":400,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"719107ca-4106-4b9d-ab39-3d6a8f96c96d"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["                                            img_path  label\n","0  /content/drive/MyDrive/50.035 Computer Vision ...  tur_N\n","1  /content/drive/MyDrive/50.035 Computer Vision ...  tur_N\n","2  /content/drive/MyDrive/50.035 Computer Vision ...  tur_N\n","3  /content/drive/MyDrive/50.035 Computer Vision ...  tur_N\n","4  /content/drive/MyDrive/50.035 Computer Vision ...  tur_N\n","DataFrame created and saved successfully!\n"]}]},{"cell_type":"code","source":["print(label_map)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6d2tDmweeHeH","executionInfo":{"status":"ok","timestamp":1734020650776,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"e4aa0dde-e668-48ee-fc9d-c7dd6a7b6493"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["{'tur_N': 0, 'tur_O': 1, 'tur_P': 2, 'tur_R': 3, 'tur_S': 4, 'tur_T': 5, 'tur_U': 6, 'tur_V': 7, 'tur_Y': 8, 'tur_Z': 9, 'tur_D': 10, 'tur_E': 11, 'tur_F': 12, 'tur_G': 13, 'tur_H': 14, 'tur_I': 15, 'tur_J': 16, 'tur_K': 17, 'tur_L': 18, 'tur_M': 19, 'bis_Q': 20, 'bis_O': 21, 'bis_T': 22, 'bis_tur_C': 23, 'bis_D': 24, 'bis_U': 25, 'bis_M': 26, 'bis_K': 27, 'bis_B': 28, 'bis_Y': 29, 'bis_S': 30, 'bis_L': 31, 'bis_F': 32, 'bis_Z': 33, 'bis_E': 34, 'bis_G': 35, 'bis_P': 36, 'bis_A': 37, 'bis_X': 38, 'bis_V': 39, 'bis_R': 40, 'bis_W': 41, 'bis_N': 42, 'bis_I': 43, 'bis_H': 44, 'tur_A': 45, 'tur_B': 46}\n"]}]},{"cell_type":"markdown","source":["## Split dataset (train, test, validate)"],"metadata":{"id":"Au9kvkgQGKQF"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# split into training+validation (90%) and testing (10%)\n","train_val_df, test_df = train_test_split(df, test_size=0.10, random_state=34, stratify=df['numeric_label'])\n","# split training+validation (90%) into training (80%) and validation (10%)\n","train_df, val_df = train_test_split(train_val_df, test_size=0.1111, random_state=34, stratify=train_val_df['numeric_label'])  # 0.1111 * 90% = ~10%\n","\n","print(f\"Training samples: {len(train_df)}\")\n","print(f\"Validation samples: {len(val_df)}\")\n","print(f\"Testing samples: {len(test_df)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YOS1XZ81h3WB","executionInfo":{"status":"ok","timestamp":1734020651621,"user_tz":-480,"elapsed":8,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"f43d72e6-e7f0-4d92-89d4-786abb47d6f4"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Training samples: 7643\n","Validation samples: 956\n","Testing samples: 956\n"]}]},{"cell_type":"markdown","source":["## Preprocessing function to load and resize image"],"metadata":{"id":"KGAm579wbFQN"}},{"cell_type":"code","source":["def preprocess_image(file_path, label):\n","    image = tf.io.read_file(file_path)\n","    image = tf.image.decode_jpeg(image, channels=3)  # use decode_png for PNG images\n","    image = tf.image.resize(image, [224, 224])\n","    image = image / 255.0  # normalize pixel values to [0, 1]\n","    return image, label"],"metadata":{"id":"B6xRcJMlbKDQ","executionInfo":{"status":"ok","timestamp":1734020652085,"user_tz":-480,"elapsed":1,"user":{"displayName":"Ad","userId":"01421917782521615893"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["## Convert dataframe to tf dataset"],"metadata":{"id":"vzCMkPWqc-04"}},{"cell_type":"code","source":["def create_dataset(df):\n","    file_paths = df['img_path'].values\n","    labels = tf.keras.utils.to_categorical(df['numeric_label'].values, num_classes=len(label_map))\n","    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n","    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","    return dataset"],"metadata":{"id":"9EMG3NvddCoY","executionInfo":{"status":"ok","timestamp":1734020653222,"user_tz":-480,"elapsed":2,"user":{"displayName":"Ad","userId":"01421917782521615893"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["## Create datasets"],"metadata":{"id":"XsW2bnzTdQ5L"}},{"cell_type":"code","source":["batch_size = 32\n","\n","train_dataset = create_dataset(train_df).shuffle(buffer_size=1000).repeat().batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n","val_dataset = create_dataset(val_df).repeat().batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n","test_dataset = create_dataset(test_df).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"],"metadata":{"id":"s3-s_PbohddI","executionInfo":{"status":"ok","timestamp":1734020654522,"user_tz":-480,"elapsed":307,"user":{"displayName":"Ad","userId":"01421917782521615893"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["## Training model"],"metadata":{"id":"8AodUoOgdUGW"}},{"cell_type":"code","source":["import math\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(len(label_map), activation='softmax')\n","])\n","\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    restore_best_weights=True\n",")\n","lr_scheduler = ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.5,\n","    patience=3,\n","    min_lr=1e-6\n",")\n","\n","# training parameters\n","epochs = 20\n","steps_per_epoch = math.ceil(len(train_df) / batch_size)\n","validation_steps = math.ceil(len(val_df) / batch_size)\n","\n","history = model.fit(\n","    train_dataset,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=epochs,\n","    validation_data=val_dataset,\n","    validation_steps=validation_steps,\n","    callbacks=[early_stopping, lr_scheduler]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eUoPsmOJijwb","executionInfo":{"status":"ok","timestamp":1734021668540,"user_tz":-480,"elapsed":110031,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"3016a9ef-a44c-4e3b-c67b-db4cc8d76558"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 0.8404 - loss: 0.7110 - val_accuracy: 0.9948 - val_loss: 0.0290 - learning_rate: 0.0010\n","Epoch 2/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9988 - loss: 0.0063 - val_accuracy: 0.9948 - val_loss: 0.0281 - learning_rate: 0.0010\n","Epoch 3/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9948 - val_loss: 0.0244 - learning_rate: 0.0010\n","Epoch 4/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.9996 - loss: 6.2200e-04 - val_accuracy: 0.9958 - val_loss: 0.0202 - learning_rate: 0.0010\n","Epoch 5/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.2125e-05 - val_accuracy: 0.9958 - val_loss: 0.0208 - learning_rate: 0.0010\n","Epoch 6/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.9064e-06 - val_accuracy: 0.9958 - val_loss: 0.0210 - learning_rate: 0.0010\n","Epoch 7/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 5.0818e-06 - val_accuracy: 0.9958 - val_loss: 0.0213 - learning_rate: 0.0010\n","Epoch 8/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.3776e-06 - val_accuracy: 0.9958 - val_loss: 0.0214 - learning_rate: 5.0000e-04\n","Epoch 9/20\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 2.7841e-06 - val_accuracy: 0.9958 - val_loss: 0.0215 - learning_rate: 5.0000e-04\n"]}]},{"cell_type":"markdown","source":["## Model Summary"],"metadata":{"id":"dNV96IVAe3lE"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"izuh-yOsep1k","executionInfo":{"status":"ok","timestamp":1734021668540,"user_tz":-480,"elapsed":24,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"67b0792d-0cb2-44d9-d845-e8ddc171168b"},"execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_13\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_26 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_27 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_13 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m186624\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m23,888,000\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m)                  │           \u001b[38;5;34m6,063\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">186624</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,888,000</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,063</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m71,740,367\u001b[0m (273.67 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,740,367</span> (273.67 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,913,455\u001b[0m (91.22 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,913,455</span> (91.22 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m47,826,912\u001b[0m (182.45 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,826,912</span> (182.45 MB)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Run model on testing"],"metadata":{"id":"X8_GJO0Cc4iX"}},{"cell_type":"code","source":["test_loss, test_accuracy = model.evaluate(test_dataset)\n","print(f\"Test Set Accuracy: {test_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uI0NkXAAdY_g","executionInfo":{"status":"ok","timestamp":1734021670551,"user_tz":-480,"elapsed":2021,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"97320620-2f02-4d89-f870-98c39bbf7549"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9966 - loss: 0.0334\n","Test Set Accuracy: 0.9979079365730286\n"]}]},{"cell_type":"markdown","source":["## Get F2 score"],"metadata":{"id":"QHXJq8P7c2S4"}},{"cell_type":"code","source":["def get_labels(dataset):\n","    labels = []\n","    for _, label in dataset:\n","        labels.append(label.numpy())\n","    return np.concatenate(labels)\n","\n","y_true = get_labels(test_dataset)\n","\n","y_pred = np.argmax(model.predict(test_dataset), axis=1)\n","\n","# ensure y_true is a 1D array of class labels (not one-hot encoded)\n","y_true = np.argmax(y_true, axis=1) if y_true.ndim > 1 else y_true"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sfniamkdcPi","executionInfo":{"status":"ok","timestamp":1734021790953,"user_tz":-480,"elapsed":2941,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"b7def430-53f4-4e77-d550-5ff10788e43e"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n"]}]},{"cell_type":"code","source":["# Compute F2 score\n","def fbeta_score(y_true, y_pred, beta=2):\n","    from sklearn.metrics import precision_recall_fscore_support\n","    precision, recall, _, _ = precision_recall_fscore_support(y_true, y_pred, beta=beta, average='weighted')\n","    fbeta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall + 1e-7)\n","    return fbeta\n","\n","f2_score = fbeta_score(y_true, y_pred, beta=2)\n","print(f\"F2 Score: {f2_score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cFXKwl8udlqc","executionInfo":{"status":"ok","timestamp":1734021673567,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"66fd9c50-7c7c-46bb-bec4-b5782607000c"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["F2 Score: 0.997927852488589\n"]}]},{"cell_type":"markdown","source":["## Save model"],"metadata":{"id":"nz0FrSpsemBA"}},{"cell_type":"code","source":["# Save the model\n","model.save(\"/content/drive/MyDrive/CompVision/doubleCNN_landmarks.h5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hGyMXLmRemSF","executionInfo":{"status":"ok","timestamp":1734021770845,"user_tz":-480,"elapsed":1089,"user":{"displayName":"Ad","userId":"01421917782521615893"}},"outputId":"13c957c3-728f-4b02-fdca-04d0f64faadd"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]}]}